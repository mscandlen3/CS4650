{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mscandlen3/CS4650/blob/main/LanguageLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YRkiFXMta2V"
      },
      "source": [
        "# NLP Analysis of Language Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueoaw1tCKFjv"
      },
      "source": [
        "*Madelyn Scandlen and Shivali Pandya*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAJZB0cTtiTh"
      },
      "source": [
        "This project seeks to perform text classification tasks on a Reddit data corpus and an Spanish learner essay corpus in order to see which language learners are the most successful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiDyqZ1ttw23"
      },
      "source": [
        "There are two main features of the project. \n",
        "\n",
        "The first task is to perform supervised classification of Spanish learners into different levels of proficiency. \n",
        "\n",
        "The second task is to classify Spanish learners into motivation profiles and evaluate the relationship between the learners' motivation and their proficiency over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLe6vDmrJ_71"
      },
      "source": [
        "## Set Up"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing Data from Google Cloud"
      ],
      "metadata": {
        "id": "hdUyih1_Svse"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w3ABQqKy-TS"
      },
      "source": [
        "This step is loading the JSON data from its location in Google Cloud Storage into this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IcZkpa-e-Fas"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKt-Cz_O6VG7",
        "outputId": "d9ff3bb5-7537-4ca6-9b42-d79ed812e9dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   443  100   443    0     0  13029      0 --:--:-- --:--:-- --:--:-- 13424\n",
            "Downloading Google Cloud SDK install script: https://dl.google.com/dl/cloudsdk/channels/rapid/install_google_cloud_sdk.bash\n",
            "\r######################################################################## 100.0%\n",
            "Running install script from: /tmp/tmp.YWR53CbOCd/install_google_cloud_sdk.bash\n",
            "which curl\n",
            "curl -# -f https://dl.google.com/dl/cloudsdk/channels/rapid/google-cloud-sdk.tar.gz\n",
            "######################################################################## 100.0%\n",
            "\n",
            "mkdir -p /root\n",
            "\"/root/google-cloud-sdk\" already exists and may contain out of date files.\n",
            "Remove /root/google-cloud-sdk or select a new installation directory, then run again.\n"
          ]
        }
      ],
      "source": [
        "!curl https://sdk.cloud.google.com | bash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW5PG0Cu-sPE",
        "outputId": "45db9f2e-7aaa-499e-ad81-d696dd9128ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome! This command will take you through the configuration of gcloud.\n",
            "\n",
            "Settings from your current configuration [default] are:\n",
            "component_manager:\n",
            "  disable_update_check: 'True'\n",
            "compute:\n",
            "  gce_metadata_read_timeout_sec: '0'\n",
            "core:\n",
            "  account: mscandlen12@gmail.com\n",
            "  project: optimal-bivouac-330014\n",
            "\n",
            "Pick configuration to use:\n",
            " [1] Re-initialize this configuration [default] with new settings \n",
            " [2] Create a new configuration\n",
            "Please enter your numeric choice:  1\n",
            "\n",
            "Your current configuration has been set to: [default]\n",
            "\n",
            "You can skip diagnostics next time by using the following flag:\n",
            "  gcloud init --skip-diagnostics\n",
            "\n",
            "Network diagnostic detects and fixes local network connection issues.\n",
            "Reachability Check passed.\n",
            "Network diagnostic passed (1/1 checks passed).\n",
            "\n",
            "Choose the account you would like to use to perform operations for this \n",
            "configuration:\n",
            " [1] mscandlen12@gmail.com\n",
            " [2] Log in with a new account\n",
            "Please enter your numeric choice:  1\n",
            "\n",
            "You are logged in as: [mscandlen12@gmail.com].\n",
            "\n",
            "Pick cloud project to use: \n",
            " [1] book-entertainment-pmlqwx\n",
            " [2] noble-nation-334716\n",
            " [3] optimal-bivouac-330014\n",
            " [4] spacetraderapp\n",
            " [5] suggest-recipe-rnunfb\n",
            " [6] the-weather-jlmknn\n",
            " [7] Create a new project\n",
            "Please enter numeric choice or text value (must exactly match list item):  3\n",
            "\n",
            "Your current project has been set to: [optimal-bivouac-330014].\n",
            "\n",
            "Not setting default zone/region (this feature makes it easier to use\n",
            "[gcloud compute] by setting an appropriate default value for the\n",
            "--zone and --region flag).\n",
            "See https://cloud.google.com/compute/docs/gcloud-compute section on how to set\n",
            "default compute region and zone manually. If you would like [gcloud init] to be\n",
            "able to do this for you the next time you run it, make sure the\n",
            "Compute Engine API is enabled for your project on the\n",
            "https://console.developers.google.com/apis page.\n",
            "\n",
            "Your Google Cloud SDK is configured and ready to use!\n",
            "\n",
            "* Commands that require authentication will use mscandlen12@gmail.com by default\n",
            "* Commands will reference project `optimal-bivouac-330014` by default\n",
            "Run `gcloud help config` to learn how to change individual settings\n",
            "\n",
            "This gcloud configuration is called [default]. You can create additional configurations if you work with multiple accounts and/or projects.\n",
            "Run `gcloud topic configurations` to learn more.\n",
            "\n",
            "Some things to try next:\n",
            "\n",
            "* Run `gcloud --help` to see the Cloud Platform services you can interact with. And run `gcloud help COMMAND` to get help on any gcloud command.\n",
            "* Run `gcloud topic --help` to learn about advanced features of the SDK like arg files and output formatting\n"
          ]
        }
      ],
      "source": [
        "!gcloud init\n",
        "# input 1, 1, optimal-bivouac-330014"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDneuUrA_TYU",
        "outputId": "659f484c-e049-4efb-cf00-5cd4d390230f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://language_learning_subreddit/2019_SUBREDDITS=learnspanish,spanish.gz...\n",
            "Copying gs://language_learning_subreddit/famous.F17.csv...\n",
            "Copying gs://language_learning_subreddit/reddit_tagged.csv...\n",
            "- [3 files][ 15.0 MiB/ 15.0 MiB]                                                \n",
            "Operation completed over 3 objects/15.0 MiB.                                     \n"
          ]
        }
      ],
      "source": [
        "!gsutil cp gs://language_learning_subreddit/2019_SUBREDDITS=learnspanish,spanish.gz gs://language_learning_subreddit/famous.F17.csv gs://language_learning_subreddit/reddit_tagged.csv ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPcGhabsRFJl"
      },
      "source": [
        "### Uploading Data to a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import gzip\n",
        "\n",
        "import re\n",
        "import string"
      ],
      "metadata": {
        "id": "JtXEQ2JHR1hz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Essay Data"
      ],
      "metadata": {
        "id": "7APcy9WMR7HZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJixtnu0I13j"
      },
      "source": [
        "In this section, we will build a corpus of Spanish words and sentences that are used by non-native spanish writers (also called L2 speakers/writers). We will use the UC Davis Corpus of Written Spanish, L2 and Heritage Speakers (COWSL2H). This corpus contains essays on the following essay prompts that were given to spanish students at UC Davis: \"famous person\", \"your perfect vacation plan\", \"a special person in your life\", and \"a terrible story\"."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_essay = pd.read_csv('./famous.F17.csv', index_col=0)\n",
        "df_essay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XaVO_qlXSB9l",
        "outputId": "65e6e3e4-e44a-44ed-baaa-0936567babf3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prompt</th>\n",
              "      <th>quarter</th>\n",
              "      <th>course</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>l1 language</th>\n",
              "      <th>other l1 language(s)</th>\n",
              "      <th>language(s) used at home</th>\n",
              "      <th>language(s) studied</th>\n",
              "      <th>listening comprehension</th>\n",
              "      <th>reading comprehension</th>\n",
              "      <th>speaking ability</th>\n",
              "      <th>writing ability</th>\n",
              "      <th>study abroad</th>\n",
              "      <th>essay</th>\n",
              "      <th>a personal annotator1</th>\n",
              "      <th>a personal annotator2</th>\n",
              "      <th>gender-number annotator1</th>\n",
              "      <th>gender-number annotator2</th>\n",
              "      <th>corrected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>146362</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 2</td>\n",
              "      <td>19</td>\n",
              "      <td>Female</td>\n",
              "      <td>English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Una persona famosa que admiro es Lauren Jaureg...</td>\n",
              "      <td>Una persona famosa que admiro es Lauren Jaureg...</td>\n",
              "      <td>Una persona famosa que admiro es Lauren Jaureg...</td>\n",
              "      <td>Una persona famosa que admiro es Lauren Jaureg...</td>\n",
              "      <td>Una persona famosa que admiro es Lauren Jaureg...</td>\n",
              "      <td>Una persona famosa que admiro es Lauren Jaureg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>104622</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 3</td>\n",
              "      <td>20</td>\n",
              "      <td>Female</td>\n",
              "      <td>English</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>No</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Yo veo un programa de television que es muy di...</td>\n",
              "      <td>Yo veo un programa de television que es muy di...</td>\n",
              "      <td>Yo veo un programa de television que es muy di...</td>\n",
              "      <td>Yo veo un programa de television que es muy di...</td>\n",
              "      <td>Yo veo un programa de television que es muy di...</td>\n",
              "      <td>Yo veo un programa de televisión que es muy di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>169693</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 24</td>\n",
              "      <td>18 as of April 2017</td>\n",
              "      <td>Female</td>\n",
              "      <td>English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Antes de contarles de una persona famosa quien...</td>\n",
              "      <td>Antes de contarles de una persona famosa quien...</td>\n",
              "      <td>Antes de contarles de una persona famosa quien...</td>\n",
              "      <td>Antes de contarles de una persona famosa quien...</td>\n",
              "      <td>Antes de contarles de una persona famosa quien...</td>\n",
              "      <td>Antes de contarles sobre una persona famosa qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>179355</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 1</td>\n",
              "      <td>20</td>\n",
              "      <td>Female</td>\n",
              "      <td>Other</td>\n",
              "      <td>Japanese</td>\n",
              "      <td>Japanese</td>\n",
              "      <td>English more than 10 years</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Voy a prensentar una chica famosa en Japón. S...</td>\n",
              "      <td>Voy a prensentar una chica famosa en Japón. S...</td>\n",
              "      <td>Voy a prensentar []{a}&lt;az:do:an&gt; una chica fa...</td>\n",
              "      <td>Voy a prensentar una chica famosa en Japón. S...</td>\n",
              "      <td>Voy a prensentar una chica famosa en Japón. S...</td>\n",
              "      <td>Voy a presentar a una chica famosa en Japón. S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>148244</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 3</td>\n",
              "      <td>19</td>\n",
              "      <td>Male</td>\n",
              "      <td>Mandarin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I speak mandarin at home</td>\n",
              "      <td>English 12 years</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Mi cantante favorita es Taylor Swift. Me gusta...</td>\n",
              "      <td>Mi cantante favorita es Taylor Swift. Me gusta...</td>\n",
              "      <td>Mi cantante favorita es Taylor Swift. Me gusta...</td>\n",
              "      <td>Mi cantante favorita es Taylor Swift. Me gusta...</td>\n",
              "      <td>Mi cantante favorita es Taylor Swift. Me gusta...</td>\n",
              "      <td>Mi cantante favorita es Taylor Swift. Me gusta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>140109</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 3</td>\n",
              "      <td>19</td>\n",
              "      <td>Male</td>\n",
              "      <td>English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Una persona Famoso: Nathan Fielder es una pers...</td>\n",
              "      <td>Una persona Famoso: Nathan Fielder es una pers...</td>\n",
              "      <td>Una persona Famoso: Nathan Fielder es una pers...</td>\n",
              "      <td>Una persona [Famoso]{famosa}&lt;ga:fm:adj:an&gt;: Na...</td>\n",
              "      <td>Una persona [Famoso]{famosa}&lt;ga:fm:adj:an&gt;: Na...</td>\n",
              "      <td>Una persona famosa: Nathan Fielder es una pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>185606</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 23</td>\n",
              "      <td>23</td>\n",
              "      <td>Female</td>\n",
              "      <td>English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Una persona famosa quien yo pienso es muy asom...</td>\n",
              "      <td>Una persona famosa quien yo pienso es muy asom...</td>\n",
              "      <td>Una persona famosa quien yo pienso es muy asom...</td>\n",
              "      <td>Una persona famosa quien yo pienso es muy asom...</td>\n",
              "      <td>Una persona famosa quien yo pienso es muy asom...</td>\n",
              "      <td>Una persona famosa muy asombrosa es Helen Kell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>156764</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 24</td>\n",
              "      <td>19</td>\n",
              "      <td>Female</td>\n",
              "      <td>English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Selena Gomez: Persona famosa\\n\\nSelena Gomez e...</td>\n",
              "      <td>Selena Gomez: Persona famosa\\n\\nSelena Gomez e...</td>\n",
              "      <td>Selena Gomez: Persona famosa\\n\\nSelena Gomez e...</td>\n",
              "      <td>Selena Gomez: Persona famosa\\n\\nSelena Gomez e...</td>\n",
              "      <td>Selena Gomez: Persona famosa\\n\\nSelena Gomez e...</td>\n",
              "      <td>Selena Gomez: Persona famosa. Selena Gomez es ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>172630</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 1</td>\n",
              "      <td>18</td>\n",
              "      <td>Female</td>\n",
              "      <td>English</td>\n",
              "      <td>none...</td>\n",
              "      <td>Spanish.</td>\n",
              "      <td>none...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Una famosa persona que yo encanta es Sabrina C...</td>\n",
              "      <td>Una famosa persona que yo encanta es Sabrina C...</td>\n",
              "      <td>Una famosa persona que yo encanta es Sabrina C...</td>\n",
              "      <td>Una famosa persona que yo encanta es Sabrina C...</td>\n",
              "      <td>Una famosa persona que yo encanta es Sabrina C...</td>\n",
              "      <td>Una famosa persona que me encanta es Sabrina C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>144920</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 3</td>\n",
              "      <td>19</td>\n",
              "      <td>Male</td>\n",
              "      <td>English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Famoso Persona\\n\\n                Mi favorito ...</td>\n",
              "      <td>Famoso Persona\\n\\n                Mi favorito ...</td>\n",
              "      <td>Famoso Persona\\n\\n                Mi favorito ...</td>\n",
              "      <td>[Famoso]{famosa}&lt;ga:fm:adj:an&gt; Persona\\n\\n    ...</td>\n",
              "      <td>[Famoso]{famosa}&lt;ga:fm:adj:an&gt; Persona\\n\\n    ...</td>\n",
              "      <td>Persona famosa. Mi persona famosa favorita es ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>175 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ...                                          corrected\n",
              "0    146362  ...  Una persona famosa que admiro es Lauren Jaureg...\n",
              "1    104622  ...  Yo veo un programa de televisión que es muy di...\n",
              "2    169693  ...  Antes de contarles sobre una persona famosa qu...\n",
              "3    179355  ...  Voy a presentar a una chica famosa en Japón. S...\n",
              "4    148244  ...  Mi cantante favorita es Taylor Swift. Me gusta...\n",
              "..      ...  ...                                                ...\n",
              "170  140109  ...  Una persona famosa: Nathan Fielder es una pers...\n",
              "171  185606  ...  Una persona famosa muy asombrosa es Helen Kell...\n",
              "172  156764  ...  Selena Gomez: Persona famosa. Selena Gomez es ...\n",
              "173  172630  ...  Una famosa persona que me encanta es Sabrina C...\n",
              "174  144920  ...  Persona famosa. Mi persona famosa favorita es ...\n",
              "\n",
              "[175 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reddit Data"
      ],
      "metadata": {
        "id": "y77szVu3SnPO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G03PoQXguOrG"
      },
      "source": [
        "The data was obtained from scraping different subreddits (r/Spanish, r/LearnSpanish) from the year 2019 and creating JSON units for each post, from [redditsearch.io](https://https://www.redditsearch.io/). Posts are both posts to the subreddit and comments. The JSONs include information such as author_tag, score (number of upvotes), and the text content of the post. \n",
        "\n",
        "To classify users, we will reorganize the JSONs to contain all posts for a user, retaining the score and the comments by other users. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xaR0ndvB_mDr"
      },
      "outputs": [],
      "source": [
        "subreddit_list = []\n",
        "\n",
        "with gzip.open('./2019_SUBREDDITS=learnspanish,spanish.gz') as f:\n",
        "  for obj in f:\n",
        "    post = json.loads(obj)\n",
        "    subreddit_list.append(post)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "LjDlvsv99wLP",
        "outputId": "85e2e81c-ec0a-48ca-ec45-ae66bcf47cdb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>author_created_utc</th>\n",
              "      <th>author_flair_background_color</th>\n",
              "      <th>author_flair_css_class</th>\n",
              "      <th>author_flair_richtext</th>\n",
              "      <th>author_flair_template_id</th>\n",
              "      <th>author_flair_text</th>\n",
              "      <th>author_flair_text_color</th>\n",
              "      <th>author_flair_type</th>\n",
              "      <th>author_fullname</th>\n",
              "      <th>author_patreon_flair</th>\n",
              "      <th>body</th>\n",
              "      <th>can_gild</th>\n",
              "      <th>can_mod_post</th>\n",
              "      <th>collapsed</th>\n",
              "      <th>collapsed_reason</th>\n",
              "      <th>controversiality</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>distinguished</th>\n",
              "      <th>edited</th>\n",
              "      <th>gilded</th>\n",
              "      <th>gildings</th>\n",
              "      <th>id</th>\n",
              "      <th>is_submitter</th>\n",
              "      <th>link_id</th>\n",
              "      <th>no_follow</th>\n",
              "      <th>parent_id</th>\n",
              "      <th>permalink</th>\n",
              "      <th>removal_reason</th>\n",
              "      <th>retrieved_on</th>\n",
              "      <th>score</th>\n",
              "      <th>send_replies</th>\n",
              "      <th>stickied</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>subreddit_id</th>\n",
              "      <th>subreddit_name_prefixed</th>\n",
              "      <th>subreddit_type</th>\n",
              "      <th>author_cakeday</th>\n",
              "      <th>quarantined</th>\n",
              "      <th>locked</th>\n",
              "      <th>all_awardings</th>\n",
              "      <th>total_awards_received</th>\n",
              "      <th>steward_reports</th>\n",
              "      <th>awarders</th>\n",
              "      <th>associated_award</th>\n",
              "      <th>collapsed_because_crowd_control</th>\n",
              "      <th>author_premium</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gloix</td>\n",
              "      <td>1.314202e+09</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>text</td>\n",
              "      <td>t2_5q1bq</td>\n",
              "      <td>False</td>\n",
              "      <td>You can say that when you've already ordered a...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>1546300964</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>{'gid_1': 0, 'gid_2': 0, 'gid_3': 0}</td>\n",
              "      <td>eczb5ii</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_aaz2g9</td>\n",
              "      <td>True</td>\n",
              "      <td>t1_ecygmis</td>\n",
              "      <td>/r/Spanish/comments/aaz2g9/when_ordering_food_...</td>\n",
              "      <td>None</td>\n",
              "      <td>1550712660</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Spanish</td>\n",
              "      <td>t5_2qtt1</td>\n",
              "      <td>r/Spanish</td>\n",
              "      <td>public</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>garbagecoder</td>\n",
              "      <td>1.434302e+09</td>\n",
              "      <td></td>\n",
              "      <td>second</td>\n",
              "      <td>[{'e': 'text', 't': 'C1'}]</td>\n",
              "      <td>None</td>\n",
              "      <td>C1</td>\n",
              "      <td>dark</td>\n",
              "      <td>richtext</td>\n",
              "      <td>t2_o3ucv</td>\n",
              "      <td>False</td>\n",
              "      <td>Thank you. There are some language where the l...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>1546301446</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>{'gid_1': 0, 'gid_2': 0, 'gid_3': 0}</td>\n",
              "      <td>eczbpj8</td>\n",
              "      <td>True</td>\n",
              "      <td>t3_ab9dr8</td>\n",
              "      <td>True</td>\n",
              "      <td>t1_ecz24yd</td>\n",
              "      <td>/r/Spanish/comments/ab9dr8/data_on_spanish_for...</td>\n",
              "      <td>None</td>\n",
              "      <td>1550712907</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Spanish</td>\n",
              "      <td>t5_2qtt1</td>\n",
              "      <td>r/Spanish</td>\n",
              "      <td>public</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gatosol</td>\n",
              "      <td>1.477917e+09</td>\n",
              "      <td>#46d160</td>\n",
              "      <td>native</td>\n",
              "      <td>[{'e': 'text', 't': '🇮🇨 Canarias (África) 🐱 Na...</td>\n",
              "      <td>ed67a04a-9a87-11e2-9ee1-12313b06caaf</td>\n",
              "      <td>🇮🇨 Canarias (África) 🐱 Native Spanish</td>\n",
              "      <td>light</td>\n",
              "      <td>richtext</td>\n",
              "      <td>t2_12hxof</td>\n",
              "      <td>False</td>\n",
              "      <td>Fast? \\n\\nhttp://www.youtube.com/watch?v=-W2NP...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>1546301848</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>{'gid_1': 0, 'gid_2': 0, 'gid_3': 0}</td>\n",
              "      <td>eczc6fx</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_abcgjr</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_abcgjr</td>\n",
              "      <td>/r/Spanish/comments/abcgjr/fast_speaking_youtu...</td>\n",
              "      <td>None</td>\n",
              "      <td>1550713115</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Spanish</td>\n",
              "      <td>t5_2qtt1</td>\n",
              "      <td>r/Spanish</td>\n",
              "      <td>public</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gloix</td>\n",
              "      <td>1.314202e+09</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>text</td>\n",
              "      <td>t2_5q1bq</td>\n",
              "      <td>False</td>\n",
              "      <td>Chile? I have never heard someone say \"me pone...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>1546301907</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>{'gid_1': 0, 'gid_2': 0, 'gid_3': 0}</td>\n",
              "      <td>eczc8r2</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_aaz2g9</td>\n",
              "      <td>True</td>\n",
              "      <td>t1_ecwk6pu</td>\n",
              "      <td>/r/Spanish/comments/aaz2g9/when_ordering_food_...</td>\n",
              "      <td>None</td>\n",
              "      <td>1550713145</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Spanish</td>\n",
              "      <td>t5_2qtt1</td>\n",
              "      <td>r/Spanish</td>\n",
              "      <td>public</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>brog88</td>\n",
              "      <td>1.499983e+09</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>text</td>\n",
              "      <td>t2_6z3h9m2</td>\n",
              "      <td>False</td>\n",
              "      <td>¡Feliz Año Nuevo! También he estado viendo las...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>1546302339</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>{'gid_1': 0, 'gid_2': 0, 'gid_3': 0}</td>\n",
              "      <td>eczcqr0</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_abcugt</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_abcugt</td>\n",
              "      <td>/r/Spanish/comments/abcugt/feliz_año_nuevo_201...</td>\n",
              "      <td>None</td>\n",
              "      <td>1550713397</td>\n",
              "      <td>9</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Spanish</td>\n",
              "      <td>t5_2qtt1</td>\n",
              "      <td>r/Spanish</td>\n",
              "      <td>public</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79886</th>\n",
              "      <td>Goatlessly</td>\n",
              "      <td>1.532500e+09</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>text</td>\n",
              "      <td>t2_1ulehyr1</td>\n",
              "      <td>False</td>\n",
              "      <td>Te lo resumo</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>1569887499</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>{}</td>\n",
              "      <td>f22emdg</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_dbff5h</td>\n",
              "      <td>True</td>\n",
              "      <td>t3_dbff5h</td>\n",
              "      <td>/r/learnspanish/comments/dbff5h/can_someone_re...</td>\n",
              "      <td>None</td>\n",
              "      <td>1578011733</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>learnspanish</td>\n",
              "      <td>t5_2rd6d</td>\n",
              "      <td>r/learnspanish</td>\n",
              "      <td>public</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79887</th>\n",
              "      <td>stvbeev</td>\n",
              "      <td>1.513914e+09</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>text</td>\n",
              "      <td>t2_4iyofhk</td>\n",
              "      <td>False</td>\n",
              "      <td>It’s usually presented as a dichotomy, but eac...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>1569887598</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>{}</td>\n",
              "      <td>f22es6l</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_dbkdc0</td>\n",
              "      <td>True</td>\n",
              "      <td>t3_dbkdc0</td>\n",
              "      <td>/r/Spanish/comments/dbkdc0/what_are_some_diffe...</td>\n",
              "      <td>None</td>\n",
              "      <td>1578011813</td>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Spanish</td>\n",
              "      <td>t5_2qtt1</td>\n",
              "      <td>r/Spanish</td>\n",
              "      <td>public</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79888</th>\n",
              "      <td>Rumope</td>\n",
              "      <td>1.397216e+09</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>text</td>\n",
              "      <td>t2_g2tva</td>\n",
              "      <td>False</td>\n",
              "      <td>Some sentences like \"A comer\" or \"A la playa\" ...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>1569887809</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>{}</td>\n",
              "      <td>f22f51w</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_db5g7n</td>\n",
              "      <td>True</td>\n",
              "      <td>t1_f227n41</td>\n",
              "      <td>/r/Spanish/comments/db5g7n/shortcut_phrases_li...</td>\n",
              "      <td>None</td>\n",
              "      <td>1578011979</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Spanish</td>\n",
              "      <td>t5_2qtt1</td>\n",
              "      <td>r/Spanish</td>\n",
              "      <td>public</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79889</th>\n",
              "      <td>KingsElite</td>\n",
              "      <td>1.343486e+09</td>\n",
              "      <td>#e87500</td>\n",
              "      <td>None</td>\n",
              "      <td>[{'e': 'text', 't': 'Perfecting it'}]</td>\n",
              "      <td>1b663862-23b7-11e4-9a5d-12313b0e94e7</td>\n",
              "      <td>Perfecting it</td>\n",
              "      <td>light</td>\n",
              "      <td>richtext</td>\n",
              "      <td>t2_8hd71</td>\n",
              "      <td>False</td>\n",
              "      <td>I studied in Xela in 2017 and felt perfectly s...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>1569887898</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>{}</td>\n",
              "      <td>f22fac8</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_dbdhx0</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_dbdhx0</td>\n",
              "      <td>/r/learnspanish/comments/dbdhx0/spanish_school...</td>\n",
              "      <td>None</td>\n",
              "      <td>1578012045</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>learnspanish</td>\n",
              "      <td>t5_2rd6d</td>\n",
              "      <td>r/learnspanish</td>\n",
              "      <td>public</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79890</th>\n",
              "      <td>grynfux</td>\n",
              "      <td>1.434911e+09</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>text</td>\n",
              "      <td>t2_o94ci</td>\n",
              "      <td>False</td>\n",
              "      <td>Ú is to denote stress on the u.\\n\\nÜ is to den...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>1569887962</td>\n",
              "      <td>None</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>{}</td>\n",
              "      <td>f22fe8g</td>\n",
              "      <td>False</td>\n",
              "      <td>t3_dbi5yz</td>\n",
              "      <td>True</td>\n",
              "      <td>t3_dbi5yz</td>\n",
              "      <td>/r/Spanish/comments/dbi5yz/what_if_there_was_a...</td>\n",
              "      <td>None</td>\n",
              "      <td>1578012096</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Spanish</td>\n",
              "      <td>t5_2qtt1</td>\n",
              "      <td>r/Spanish</td>\n",
              "      <td>public</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>79891 rows × 47 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             author  ...  author_premium\n",
              "0             gloix  ...             NaN\n",
              "1      garbagecoder  ...             NaN\n",
              "2           gatosol  ...             NaN\n",
              "3             gloix  ...             NaN\n",
              "4            brog88  ...             NaN\n",
              "...             ...  ...             ...\n",
              "79886    Goatlessly  ...           False\n",
              "79887       stvbeev  ...           False\n",
              "79888        Rumope  ...           False\n",
              "79889    KingsElite  ...           False\n",
              "79890       grynfux  ...           False\n",
              "\n",
              "[79891 rows x 47 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_reddit = pd.DataFrame(subreddit_list)\n",
        "df_reddit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tagged = pd.read_csv('./reddit_tagged.csv', index_col=0)"
      ],
      "metadata": {
        "id": "wU3pbVpYOabF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV705xv1Iv02"
      },
      "source": [
        "## Task 1: Classifying Users by Proficiency Level\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the Data"
      ],
      "metadata": {
        "id": "4iyQVaNETlES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_essay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cqoRVEKGTkDu",
        "outputId": "4067ee54-d548-4750-8848-da5c28c2fac7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prompt</th>\n",
              "      <th>quarter</th>\n",
              "      <th>course</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>l1 language</th>\n",
              "      <th>other l1 language(s)</th>\n",
              "      <th>language(s) used at home</th>\n",
              "      <th>language(s) studied</th>\n",
              "      <th>listening comprehension</th>\n",
              "      <th>reading comprehension</th>\n",
              "      <th>speaking ability</th>\n",
              "      <th>writing ability</th>\n",
              "      <th>study abroad</th>\n",
              "      <th>essay</th>\n",
              "      <th>a personal annotator1</th>\n",
              "      <th>a personal annotator2</th>\n",
              "      <th>gender-number annotator1</th>\n",
              "      <th>gender-number annotator2</th>\n",
              "      <th>corrected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>146362</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 2</td>\n",
              "      <td>19</td>\n",
              "      <td>Female</td>\n",
              "      <td>English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Una persona famosa que admiro es Lauren Jaureg...</td>\n",
              "      <td>Una persona famosa que admiro es Lauren Jaureg...</td>\n",
              "      <td>Una persona famosa que admiro es Lauren Jaureg...</td>\n",
              "      <td>Una persona famosa que admiro es Lauren Jaureg...</td>\n",
              "      <td>Una persona famosa que admiro es Lauren Jaureg...</td>\n",
              "      <td>Una persona famosa que admiro es Lauren Jaureg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>104622</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 3</td>\n",
              "      <td>20</td>\n",
              "      <td>Female</td>\n",
              "      <td>English</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>No</td>\n",
              "      <td>Not Applicable</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Yo veo un programa de television que es muy di...</td>\n",
              "      <td>Yo veo un programa de television que es muy di...</td>\n",
              "      <td>Yo veo un programa de television que es muy di...</td>\n",
              "      <td>Yo veo un programa de television que es muy di...</td>\n",
              "      <td>Yo veo un programa de television que es muy di...</td>\n",
              "      <td>Yo veo un programa de televisión que es muy di...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>169693</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 24</td>\n",
              "      <td>18 as of April 2017</td>\n",
              "      <td>Female</td>\n",
              "      <td>English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Antes de contarles de una persona famosa quien...</td>\n",
              "      <td>Antes de contarles de una persona famosa quien...</td>\n",
              "      <td>Antes de contarles de una persona famosa quien...</td>\n",
              "      <td>Antes de contarles de una persona famosa quien...</td>\n",
              "      <td>Antes de contarles de una persona famosa quien...</td>\n",
              "      <td>Antes de contarles sobre una persona famosa qu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>179355</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 1</td>\n",
              "      <td>20</td>\n",
              "      <td>Female</td>\n",
              "      <td>Other</td>\n",
              "      <td>Japanese</td>\n",
              "      <td>Japanese</td>\n",
              "      <td>English more than 10 years</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Voy a prensentar una chica famosa en Japón. S...</td>\n",
              "      <td>Voy a prensentar una chica famosa en Japón. S...</td>\n",
              "      <td>Voy a prensentar []{a}&lt;az:do:an&gt; una chica fa...</td>\n",
              "      <td>Voy a prensentar una chica famosa en Japón. S...</td>\n",
              "      <td>Voy a prensentar una chica famosa en Japón. S...</td>\n",
              "      <td>Voy a presentar a una chica famosa en Japón. S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>148244</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 3</td>\n",
              "      <td>19</td>\n",
              "      <td>Male</td>\n",
              "      <td>Mandarin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I speak mandarin at home</td>\n",
              "      <td>English 12 years</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Mi cantante favorita es Taylor Swift. Me gusta...</td>\n",
              "      <td>Mi cantante favorita es Taylor Swift. Me gusta...</td>\n",
              "      <td>Mi cantante favorita es Taylor Swift. Me gusta...</td>\n",
              "      <td>Mi cantante favorita es Taylor Swift. Me gusta...</td>\n",
              "      <td>Mi cantante favorita es Taylor Swift. Me gusta...</td>\n",
              "      <td>Mi cantante favorita es Taylor Swift. Me gusta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>140109</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 3</td>\n",
              "      <td>19</td>\n",
              "      <td>Male</td>\n",
              "      <td>English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Una persona Famoso: Nathan Fielder es una pers...</td>\n",
              "      <td>Una persona Famoso: Nathan Fielder es una pers...</td>\n",
              "      <td>Una persona Famoso: Nathan Fielder es una pers...</td>\n",
              "      <td>Una persona [Famoso]{famosa}&lt;ga:fm:adj:an&gt;: Na...</td>\n",
              "      <td>Una persona [Famoso]{famosa}&lt;ga:fm:adj:an&gt;: Na...</td>\n",
              "      <td>Una persona famosa: Nathan Fielder es una pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>185606</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 23</td>\n",
              "      <td>23</td>\n",
              "      <td>Female</td>\n",
              "      <td>English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Una persona famosa quien yo pienso es muy asom...</td>\n",
              "      <td>Una persona famosa quien yo pienso es muy asom...</td>\n",
              "      <td>Una persona famosa quien yo pienso es muy asom...</td>\n",
              "      <td>Una persona famosa quien yo pienso es muy asom...</td>\n",
              "      <td>Una persona famosa quien yo pienso es muy asom...</td>\n",
              "      <td>Una persona famosa muy asombrosa es Helen Kell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>156764</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 24</td>\n",
              "      <td>19</td>\n",
              "      <td>Female</td>\n",
              "      <td>English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Selena Gomez: Persona famosa\\n\\nSelena Gomez e...</td>\n",
              "      <td>Selena Gomez: Persona famosa\\n\\nSelena Gomez e...</td>\n",
              "      <td>Selena Gomez: Persona famosa\\n\\nSelena Gomez e...</td>\n",
              "      <td>Selena Gomez: Persona famosa\\n\\nSelena Gomez e...</td>\n",
              "      <td>Selena Gomez: Persona famosa\\n\\nSelena Gomez e...</td>\n",
              "      <td>Selena Gomez: Persona famosa. Selena Gomez es ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>172630</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 1</td>\n",
              "      <td>18</td>\n",
              "      <td>Female</td>\n",
              "      <td>English</td>\n",
              "      <td>none...</td>\n",
              "      <td>Spanish.</td>\n",
              "      <td>none...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Una famosa persona que yo encanta es Sabrina C...</td>\n",
              "      <td>Una famosa persona que yo encanta es Sabrina C...</td>\n",
              "      <td>Una famosa persona que yo encanta es Sabrina C...</td>\n",
              "      <td>Una famosa persona que yo encanta es Sabrina C...</td>\n",
              "      <td>Una famosa persona que yo encanta es Sabrina C...</td>\n",
              "      <td>Una famosa persona que me encanta es Sabrina C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>144920</td>\n",
              "      <td>famous</td>\n",
              "      <td>F17</td>\n",
              "      <td>SPA 3</td>\n",
              "      <td>19</td>\n",
              "      <td>Male</td>\n",
              "      <td>English</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Famoso Persona\\n\\n                Mi favorito ...</td>\n",
              "      <td>Famoso Persona\\n\\n                Mi favorito ...</td>\n",
              "      <td>Famoso Persona\\n\\n                Mi favorito ...</td>\n",
              "      <td>[Famoso]{famosa}&lt;ga:fm:adj:an&gt; Persona\\n\\n    ...</td>\n",
              "      <td>[Famoso]{famosa}&lt;ga:fm:adj:an&gt; Persona\\n\\n    ...</td>\n",
              "      <td>Persona famosa. Mi persona famosa favorita es ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>175 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ...                                          corrected\n",
              "0    146362  ...  Una persona famosa que admiro es Lauren Jaureg...\n",
              "1    104622  ...  Yo veo un programa de televisión que es muy di...\n",
              "2    169693  ...  Antes de contarles sobre una persona famosa qu...\n",
              "3    179355  ...  Voy a presentar a una chica famosa en Japón. S...\n",
              "4    148244  ...  Mi cantante favorita es Taylor Swift. Me gusta...\n",
              "..      ...  ...                                                ...\n",
              "170  140109  ...  Una persona famosa: Nathan Fielder es una pers...\n",
              "171  185606  ...  Una persona famosa muy asombrosa es Helen Kell...\n",
              "172  156764  ...  Selena Gomez: Persona famosa. Selena Gomez es ...\n",
              "173  172630  ...  Una famosa persona que me encanta es Sabrina C...\n",
              "174  144920  ...  Persona famosa. Mi persona famosa favorita es ...\n",
              "\n",
              "[175 rows x 21 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first start by taking the mean of the listeners' ability scores and rounding that be an integer score. This will be used as our ordered, categorical labels for proficiency classification, {1,2,3,4,5} with 5 being most proficient and 1 being least proficient."
      ],
      "metadata": {
        "id": "nAdUUnE0T1dU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBTOOW9A4R25",
        "outputId": "e941354a-0f4b-4ae9-b9dc-59c694ab2e9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "df_e = df_essay\n",
        "df_e['score'] = df_essay[['listening comprehension', 'reading comprehension', 'speaking ability', 'writing ability']].mean(axis=1)\n",
        "df_e = df_e.dropna(axis=0, subset=['score'])\n",
        "df_e['score'] = df_e['score'].round(0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Cerp8OvX6XR0",
        "outputId": "cd23d3bc-98e0-4600-ca5c-695ca1068ce6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>course</th>\n",
              "      <th>essay</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>146362</td>\n",
              "      <td>SPA 2</td>\n",
              "      <td>Una persona famosa que admiro es Lauren Jaureg...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>104622</td>\n",
              "      <td>SPA 3</td>\n",
              "      <td>Yo veo un programa de television que es muy di...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>169693</td>\n",
              "      <td>SPA 24</td>\n",
              "      <td>Antes de contarles de una persona famosa quien...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>179355</td>\n",
              "      <td>SPA 1</td>\n",
              "      <td>Voy a prensentar una chica famosa en Japón. S...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>148244</td>\n",
              "      <td>SPA 3</td>\n",
              "      <td>Mi cantante favorita es Taylor Swift. Me gusta...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>140109</td>\n",
              "      <td>SPA 3</td>\n",
              "      <td>Una persona Famoso: Nathan Fielder es una pers...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>185606</td>\n",
              "      <td>SPA 23</td>\n",
              "      <td>Una persona famosa quien yo pienso es muy asom...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>156764</td>\n",
              "      <td>SPA 24</td>\n",
              "      <td>Selena Gomez: Persona famosa\\n\\nSelena Gomez e...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>172630</td>\n",
              "      <td>SPA 1</td>\n",
              "      <td>Una famosa persona que yo encanta es Sabrina C...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>144920</td>\n",
              "      <td>SPA 3</td>\n",
              "      <td>Famoso Persona\\n\\n                Mi favorito ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>164 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  course                                              essay  score\n",
              "0    146362   SPA 2  Una persona famosa que admiro es Lauren Jaureg...      2\n",
              "1    104622   SPA 3  Yo veo un programa de television que es muy di...      3\n",
              "2    169693  SPA 24  Antes de contarles de una persona famosa quien...      3\n",
              "3    179355   SPA 1   Voy a prensentar una chica famosa en Japón. S...      2\n",
              "4    148244   SPA 3  Mi cantante favorita es Taylor Swift. Me gusta...      4\n",
              "..      ...     ...                                                ...    ...\n",
              "170  140109   SPA 3  Una persona Famoso: Nathan Fielder es una pers...      4\n",
              "171  185606  SPA 23  Una persona famosa quien yo pienso es muy asom...      2\n",
              "172  156764  SPA 24  Selena Gomez: Persona famosa\\n\\nSelena Gomez e...      2\n",
              "173  172630   SPA 1  Una famosa persona que yo encanta es Sabrina C...      2\n",
              "174  144920   SPA 3  Famoso Persona\\n\\n                Mi favorito ...      2\n",
              "\n",
              "[164 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df_e = df_e[['id', 'course', 'essay', 'score']]\n",
        "df_e"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are also extracting the Spanish level course number using Regex. We are only extracting the first digit to have three courses {1,2,3}."
      ],
      "metadata": {
        "id": "HRhRWclnVd7M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "HUVKLGAa85ze",
        "outputId": "9b0d6c5f-46d8-4f7c-8060-8542cdea015a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>course</th>\n",
              "      <th>essay</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>146362</td>\n",
              "      <td>2</td>\n",
              "      <td>Una persona famosa que admiro es Lauren Jaureg...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>104622</td>\n",
              "      <td>3</td>\n",
              "      <td>Yo veo un programa de television que es muy di...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>169693</td>\n",
              "      <td>2</td>\n",
              "      <td>Antes de contarles de una persona famosa quien...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>179355</td>\n",
              "      <td>1</td>\n",
              "      <td>Voy a prensentar una chica famosa en Japón. S...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>148244</td>\n",
              "      <td>3</td>\n",
              "      <td>Mi cantante favorita es Taylor Swift. Me gusta...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>140109</td>\n",
              "      <td>3</td>\n",
              "      <td>Una persona Famoso: Nathan Fielder es una pers...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>185606</td>\n",
              "      <td>2</td>\n",
              "      <td>Una persona famosa quien yo pienso es muy asom...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>156764</td>\n",
              "      <td>2</td>\n",
              "      <td>Selena Gomez: Persona famosa\\n\\nSelena Gomez e...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>172630</td>\n",
              "      <td>1</td>\n",
              "      <td>Una famosa persona que yo encanta es Sabrina C...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>144920</td>\n",
              "      <td>3</td>\n",
              "      <td>Famoso Persona\\n\\n                Mi favorito ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>164 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id course                                              essay  score\n",
              "0    146362      2  Una persona famosa que admiro es Lauren Jaureg...      2\n",
              "1    104622      3  Yo veo un programa de television que es muy di...      3\n",
              "2    169693      2  Antes de contarles de una persona famosa quien...      3\n",
              "3    179355      1   Voy a prensentar una chica famosa en Japón. S...      2\n",
              "4    148244      3  Mi cantante favorita es Taylor Swift. Me gusta...      4\n",
              "..      ...    ...                                                ...    ...\n",
              "170  140109      3  Una persona Famoso: Nathan Fielder es una pers...      4\n",
              "171  185606      2  Una persona famosa quien yo pienso es muy asom...      2\n",
              "172  156764      2  Selena Gomez: Persona famosa\\n\\nSelena Gomez e...      2\n",
              "173  172630      1  Una famosa persona que yo encanta es Sabrina C...      2\n",
              "174  144920      3  Famoso Persona\\n\\n                Mi favorito ...      2\n",
              "\n",
              "[164 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df_e['course'] = df_e['course'].str.replace(r\"(SPA\\s)(\\d)([0-9]*)\", r\"\\2\")\n",
        "df_e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKxbVa4qCRvc"
      },
      "source": [
        "### Creating LSTM to do Document Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkuAt3-NI1_d"
      },
      "source": [
        "Following the tutorial to create a Bidirectional LSTM from https://towardsdatascience.com/multi-class-text-classification-with-lstm-using-tensorflow-2-0-d88627c10a35 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEP655FkCa9G",
        "outputId": "277926d7-457d-44cc-b030-e360197da2f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional, Embedding\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "STOPWORDS = set(stopwords.words('english') + stopwords.words('spanish'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we iterate over every essay and remove the stopwords and append it to our docs list."
      ],
      "metadata": {
        "id": "gMIKUdaeWlbX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1QXBP_vA8bJ",
        "outputId": "9339f53e-e6f3-4400-9a65-4c6af3d32017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164\n"
          ]
        }
      ],
      "source": [
        "docs_e = []\n",
        "for doc in df_e['essay']:\n",
        "  for word in STOPWORDS:\n",
        "    token = ' ' + word + ' '\n",
        "    doc = doc.replace(token, ' ')\n",
        "    doc = doc.replace(' ', ' ')\n",
        "  docs_e.append(doc)\n",
        "print(len(docs_e))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are subtracting 1 from the labels so that our classes begin at 0. We will then one-hot encode our classes, assuming they resemble Likert scale measures of proficiency."
      ],
      "metadata": {
        "id": "CosCMo_gYCIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_e = df_e['score'] - 1\n",
        "print(len(labels_e))\n",
        "print(labels_e[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2PX7C-4Wi5l",
        "outputId": "4b317fc1-319b-4d97-f8d9-1e7d33a883e6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164\n",
            "0    1\n",
            "1    2\n",
            "2    2\n",
            "3    1\n",
            "4    3\n",
            "Name: score, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_encoded = to_categorical(labels_e)\n",
        "print(len(labels_encoded))\n",
        "print(labels_encoded[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIkruySuZ5Ni",
        "outputId": "15b6463d-3614-4467-f2e0-f93581b2572f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(df_e['score'] - 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shu2r6dWaYVC",
        "outputId": "af91a00f-ad8c-412c-c230-dcd8cca755dd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1, 2, 3, 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FTkUEL3gBySC"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "vocab_size = 500\n",
        "embedding_dim = 64\n",
        "max_length = 200\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = '<OOV>'\n",
        "training_portion = .8"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will print out a list of all the word tokens and their indices."
      ],
      "metadata": {
        "id": "ygSSHWyyXRTQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOC2vhtnDNXA",
        "outputId": "0e32f8a3-cbc0-4929-e527-6fff49ab9b8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<OOV>': 1,\n",
              " 'años': 9,\n",
              " 'canciones': 15,\n",
              " 'dos': 16,\n",
              " 'el': 3,\n",
              " 'ella': 2,\n",
              " 'en': 12,\n",
              " 'famosa': 7,\n",
              " 'famoso': 18,\n",
              " 'gusta': 5,\n",
              " 'muchas': 11,\n",
              " 'música': 13,\n",
              " 'película': 17,\n",
              " 'persona': 6,\n",
              " 'personas': 8,\n",
              " 'ser': 14,\n",
              " 'su': 10,\n",
              " 'también': 20,\n",
              " 'vida': 19,\n",
              " 'él': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(docs_e)\n",
        "word_index = tokenizer.word_index\n",
        "dict(list(word_index.items())[0:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1Z9i_eWsESTT"
      },
      "outputs": [],
      "source": [
        "padded_docs_e = pad_sequences(tokenizer.texts_to_sequences(docs_e), maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_seq_e = np.array(labels_encoded)"
      ],
      "metadata": {
        "id": "FatSAln5a_Cl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(Bidirectional(LSTM(embedding_dim)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaI3dr_DhlHl",
        "outputId": "1100cd46-5f80-4c92-b27b-245f8c60718a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 64)          32000     \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              66048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 98,693\n",
            "Trainable params: 98,693\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(padded_docs_e, label_seq_e, epochs=20, validation_split=0.2)"
      ],
      "metadata": {
        "id": "tsR6dCtJmB1g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b45506-43c7-43fe-df35-b8419b82134d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgQ78YZIGPtV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "  \n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results of the LSTM performing supervised classification."
      ],
      "metadata": {
        "id": "nXCwVonTmsBz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzZlkN-gI9xW"
      },
      "source": [
        "## Task 2: Figuring out how to classify Learners by Motivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqiQAsQPuLLZ"
      },
      "source": [
        "### Pre-Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_reddit"
      ],
      "metadata": {
        "id": "hktdHvLInG8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4CVa8zrB_Sj"
      },
      "source": [
        "First, we will specify which columns to keep, dropping unimportant information to our task about background text and gildings. Then we are dropping posts that have a deleted author since we won't be able to connect it to other posts. We are also adding a column to reformat the timestamp when the post was created. We are then going to index by the author id to keep a hierarchy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlJbtdXHrBS9"
      },
      "outputs": [],
      "source": [
        "df_r = df_reddit[['author', 'author_fullname', 'author_flair_text', 'id', 'body', 'created_utc', 'is_submitter', 'link_id', 'no_follow', 'parent_id', 'permalink', 'score', 'subreddit', 'subreddit_id']]\n",
        "df_r = df_r.dropna(axis=0, subset=['author_fullname', 'author'])\n",
        "\n",
        "df_r = df_r.sort_values(['author_fullname'])\n",
        "df_r = df_r.set_index(['author_fullname', 'id'])\n",
        "df_r"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are adding a timestamp to our posts so that we can have understanding of when the post was made."
      ],
      "metadata": {
        "id": "eT3kpywdn6BF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxXqEujv_vlM"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timezone\n",
        "\n",
        "utcs = (df_r['created_utc'].astype(int))\n",
        "ts = []\n",
        "month = []\n",
        "for u in utcs:\n",
        "   t = datetime.fromtimestamp(u, tz=timezone.utc)\n",
        "   ts.append(t)\n",
        "   month.append(datetime.strftime(t, '%m'))\n",
        "\n",
        "df_r['timestamp'] = ts\n",
        "df_r['month'] = month"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn9aD2azJx0L"
      },
      "source": [
        "### Looking at Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary Data"
      ],
      "metadata": {
        "id": "EXBIS3q5R0d1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzlPE_7j-UgK"
      },
      "source": [
        "Now we are going to look at summary statistics for the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_jJPtCHLBuP"
      },
      "outputs": [],
      "source": [
        "print(\"There are\", df_r.author.nunique(), \"users in the dataset.\\n\")\n",
        "\n",
        "subreddit_user_count = list(df_r['subreddit'].value_counts())\n",
        "\n",
        "print(\"There are\", subreddit_user_count[0], \"posts from the r/Spanish subreddit\")\n",
        "print(\"There are\", subreddit_user_count[1], \"posts from the r/learninspanish subreddit\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrRJNCm4BvaQ"
      },
      "outputs": [],
      "source": [
        "# Most common author flairs\n",
        "df_r['author_flair_text'].value_counts()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Average posts by a user\n",
        "df_r.groupby(['author']).size().mean()"
      ],
      "metadata": {
        "id": "foRfLiJKQL4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average length of a text post in characters\n",
        "df_r['body'].str.len().mean()"
      ],
      "metadata": {
        "id": "l9IYC2jfRchW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sample User Data"
      ],
      "metadata": {
        "id": "Y2hPJqZ5RxSM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqe7RPfeyZS5"
      },
      "source": [
        "Here we can isolate a random user ('gatosol', 't2_12hxof) and try to get an idea of what information we get from their profile and posts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20C1SAd6tRBe"
      },
      "outputs": [],
      "source": [
        "user_sample = df_r.loc['t2_12hxof'].reset_index()\n",
        "user_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Z4D6URFXae"
      },
      "source": [
        "We see that from the author_flair_text that they are a native speaker of Spanish, and therefore are not learning. We will eventually have to throw out this user, but we can do this with NLP processing by classifying a user as a learner or a native speaker."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF0SutsuFmJY"
      },
      "source": [
        "Let's look at a user that we know is a learner, user LangGeek ('t2_zzree'). Their flair identifies them as a B2 learner which means that they are \"vantage or upper intermediate\" level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPkwIEnrFv9B"
      },
      "outputs": [],
      "source": [
        "user_sample = df_r.loc['t2_zzree'].reset_index()\n",
        "user_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mrz_RoFF6v4"
      },
      "source": [
        "Let's look at their post (id='eldx5a') to see what information they've shared about their learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6CNJAHlGIX2"
      },
      "outputs": [],
      "source": [
        "for i in range(len(user_sample)):\n",
        "  post = user_sample.iloc[i]\n",
        "  print(post['id'], \": \", post['body'], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G62gPaOyHj2k"
      },
      "source": [
        "We see that they've been learning for 7 years ('eldx5a0'), that they \"speak like an Argentinian\" but have a hard time understanding other Argentinians ('eibf8z7'), and that they talk to themselves in their head to faciliate learning ('euotx3g'). These comments also highlight differences in learning Spanish that is spoken in different countries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SedZyU7kIBD8"
      },
      "source": [
        "There's not much about user 't2_zzree's personal motivation in this post though there is an implication of learning for someone that the user is interested in communicating with."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Extracting out Learners"
      ],
      "metadata": {
        "id": "yzTApIuvS3qd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pER_UjXMHSm"
      },
      "outputs": [],
      "source": [
        "df_r.fillna(\"\",inplace=True)\n",
        "\n",
        "df_r['author_flair_text'] = df_r['author_flair_text'].str.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are performing regex pattern matching to find a subset of users that are blatantly identified as learners."
      ],
      "metadata": {
        "id": "f8NDH2QuTKgE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwK8ZHBk9n3N"
      },
      "outputs": [],
      "source": [
        "patterns = [r\"learner\", r\"heritage\", r\"native\",r\"[a-z]{1}[0-2]{1}\", r\"student\", r\"beginner\", r\"intermediate\", r\"advanced\"]\n",
        "\n",
        "flair_patterns = '|'.join(patterns)\n",
        "df_r['learner'] =  df_r['author_flair_text'].str.contains(flair_patterns)\n",
        "df_r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_t5QQBCNcVV"
      },
      "outputs": [],
      "source": [
        "df_learner = df_r.loc[df_r['learner']]\n",
        "df_learner = df_learner.drop(columns=['learner'])\n",
        "df_learner.set_index('author')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxlVVks-szY3"
      },
      "outputs": [],
      "source": [
        "out = open('reddit_learners.csv', 'w')\n",
        "df_learner.to_csv(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dswXt5UPFVQJ"
      },
      "source": [
        "#### Manually annotating posts with motivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_-lI9SFFlMm"
      },
      "source": [
        "1. Go through posts and classify them as hasMotivation (true, false) based on having the above regex words.\n",
        "2. Then from posts that do have motivation, combine to be one document for a user.\n",
        "3. Transform the posts to vectors using word2vec\n",
        "4. perform K-means clustering on the users' posts in vector space\n",
        "5. Use Elbow criterion to find best clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now importing a CSV that was manually annotated to assign each post to a motivation profile. The meanings of the labels are as follows:\n",
        "\n",
        "\n",
        "\n",
        "0.   No mention of motivation\n",
        "1.   Culture\n",
        "2.   Dating & Family\n",
        "3.   School & Lessons\n",
        "4.   Career\n",
        "5.   Travel\n",
        "6.   Heritage"
      ],
      "metadata": {
        "id": "4TbE800oV487"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8uIb6hKp-Ho"
      },
      "outputs": [],
      "source": [
        "df_reddit_tagged = pd.read_csv('reddit_tagged.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_learner.shape)\n",
        "print(df_reddit_tagged.shape)"
      ],
      "metadata": {
        "id": "Z-EuH7xTUBWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using about 5% of posts from learners that have annotations. This could potentially be used for semi-supervised learning if our model fits to supervised learning well."
      ],
      "metadata": {
        "id": "hLWTcw4fUOoD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGmtjBxluZNC"
      },
      "outputs": [],
      "source": [
        "df_tagged = df_reddit_tagged[['author','author_flair_text','body','created_utc','class']]\n",
        "df_tagged = df_tagged.dropna()\n",
        "df_tagged['class'] = df_tagged['class'].astype(int)\n",
        "df_tagged"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Most common author flairs\n",
        "df_tagged['author_flair_text'].value_counts()[:10]"
      ],
      "metadata": {
        "id": "SFPBl1NDW8pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oB_Xnytx3vYd"
      },
      "outputs": [],
      "source": [
        "user_sample = df_tagged.loc[df_tagged['author'] == 'oldskoolgeometro']\n",
        "user_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we look at user 'oldskoolgeometro' who has identified themselves as a \"beginner\" and \"learner (a1)\"."
      ],
      "metadata": {
        "id": "vXldy_mOVQKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of their posts are tagged 0 for no motivation, but the below post is labeled for class 5: \"travel\"."
      ],
      "metadata": {
        "id": "qsFoarIaVYxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(user_sample.loc[16]['body'])\n",
        "print(user_sample.loc[16]['class'])"
      ],
      "metadata": {
        "id": "W0R2sNBeVhBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will drop all posts that are labeled 0 for having no motivation. We are then going to subtract 1 from all labels to start our classes at 0."
      ],
      "metadata": {
        "id": "u3CeANRsWd9l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2ODNZ8JilcE"
      },
      "outputs": [],
      "source": [
        "df_motiv = df_tagged.where(df_tagged['class'] > 0, None)\n",
        "df_motiv = df_motiv.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_motiv['class'] = df_motiv['class'] - 1\n",
        "df_motiv"
      ],
      "metadata": {
        "id": "U8iXE9EHXhvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.countplot(x='class', data=df_motiv)"
      ],
      "metadata": {
        "id": "GXJBUFgFX8l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have classes represented.\n",
        "\n",
        "0.   Culture\n",
        "1.   Dating & Family\n",
        "2.   School & Lessons\n",
        "3.   Career\n",
        "4.   Travel\n",
        "5.   Heritage"
      ],
      "metadata": {
        "id": "4fWJtGPJXpiK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIzLk7dEMWHK"
      },
      "source": [
        "### Initial Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we are going to clean up the text data."
      ],
      "metadata": {
        "id": "Cyx2MeAHYtJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_motiv"
      ],
      "metadata": {
        "id": "viS8dM58Y1lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRY-63MTgdA6"
      },
      "outputs": [],
      "source": [
        "texts=[]\n",
        "for text in df['body']:\n",
        "  text = re.sub(r\"[{}]\".format(string.punctuation), \" \", text.lower())\n",
        "  text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
        "  text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
        "  texts.append(text)\n",
        "\n",
        "df['body'] = texts\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.asarray(df['class']).astype(int)\n",
        "labels[:5]"
      ],
      "metadata": {
        "id": "hr-q85iYedb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Vectorizing with Tf-Idf"
      ],
      "metadata": {
        "id": "QOiho5WIZGxr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAbq-hUWNL8o"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidfvect = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.8, stop_words=['english','spanish'], use_idf=True)\n",
        "tfidf = tfidfvect.fit_transform(df['body'])\n",
        "\n",
        "print(tfidf.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 222 samples that have 535 features."
      ],
      "metadata": {
        "id": "nFhol2UEZjRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.loc[0]['body'])\n",
        "x = pd.DataFrame(tfidf[0].T.todense(), index = tfidfvect.get_feature_names_out(), columns = ['tfidf'])\n",
        "x = x.sort_values(by = ['tfidf'], ascending=False)\n",
        "print(x[:5])\n",
        "print(\"\\nLabel: \", labels[0])"
      ],
      "metadata": {
        "id": "qNKwhYnkZe6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scatterplot Using Actual Labels"
      ],
      "metadata": {
        "id": "Az3sXfywbyu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "4FU1IlaldjcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We train the PCA on the dense version of the tf-idf. \n",
        "pca = PCA(n_components=len(labels))\n",
        "two_dim = pca.fit_transform(tfidf.todense())\n",
        "\n",
        "scatter_x = two_dim[:, 0] # first principle component\n",
        "scatter_y = two_dim[:, 1] # second principle component"
      ],
      "metadata": {
        "id": "EoDNt7qHcRZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd7TfpaocGo5"
      },
      "outputs": [],
      "source": [
        "plt.style.use('ggplot')\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(20,10)\n",
        "\n",
        "# color map for NUMBER_OF_CLUSTERS we have\n",
        "cmap = {0: 'green', 1: 'blue', 2: 'red', 3: 'yellow', 4: \"pink\", 5:\"black\"}\n",
        "\n",
        "# group by clusters and scatter plot every cluster\n",
        "# with a colour and a label\n",
        "for group in np.unique(labels):\n",
        "    ix = np.where(labels == group)\n",
        "    ax.scatter(scatter_x[ix], scatter_y[ix], c=cmap[group], label=group)\n",
        "\n",
        "ax.legend()\n",
        "plt.xlabel(\"PCA 0\")\n",
        "plt.ylabel(\"PCA 1\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### K-Means Clustering & PCA"
      ],
      "metadata": {
        "id": "jo33X03qYgsG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mn2La3pfMdx0"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e89RfQDN75k"
      },
      "outputs": [],
      "source": [
        "num=6\n",
        "\n",
        "kmeans = KMeans(n_clusters = num, init='k-means++', max_iter = 15).fit(tfidf)\n",
        "print(kmeans.cluster_centers_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOqphH1qXRpy"
      },
      "outputs": [],
      "source": [
        "predicting = [df.iloc[0]['body'], df.iloc[1]['body'], df.iloc[2]['body'], df.iloc[3]['body']]\n",
        "print(\"author \", df.iloc[0]['author'], \": \", df.iloc[0]['body'])\n",
        "print(\"author \", df.iloc[1]['author'], \": \", df.iloc[1]['body'])\n",
        "print(\"author \", df.iloc[2]['author'], \": \", df.iloc[2]['body'])\n",
        "print(\"author \", df.iloc[3]['author'], \": \", df.iloc[3]['body'])\n",
        "pred = kmeans.predict(tfidfvect.transform(predicting))\n",
        "actual = [labels[0], labels[1], labels[2], labels[3]]\n",
        "\n",
        "print(\"\\nPredicted Labels by K-Means: \", pred)\n",
        "print(\"\\nActual Labels: \", actual)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means is not trying to predict labels, just clustering, but it did not cluster the same labels that the annotators had."
      ],
      "metadata": {
        "id": "IIu1DwdVa5ma"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIt2oH1iZFRj"
      },
      "outputs": [],
      "source": [
        "# First: for every document we get its corresponding cluster\n",
        "clusters = kmeans.predict(tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsraS3fWTYK4"
      },
      "outputs": [],
      "source": [
        "preds = pd.DataFrame(clusters, columns=['cluster'])\n",
        "sns.countplot(x='cluster', data=preds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We train the PCA on the dense version of the tf-idf. \n",
        "pca = PCA(n_components=num)\n",
        "two_dim = pca.fit_transform(tfidf.todense())\n",
        "\n",
        "scatter_x = two_dim[:, 0] # first principle component\n",
        "scatter_y = two_dim[:, 1] # second principle component"
      ],
      "metadata": {
        "id": "-icxVDICbYLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCNCUGdCShrW"
      },
      "outputs": [],
      "source": [
        "print(pca.explained_variance_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytaojx5KSnaV"
      },
      "outputs": [],
      "source": [
        "# plot the cumulative explained variance\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance');\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF32wTCfSr2l"
      },
      "outputs": [],
      "source": [
        "# Plot the explained variances\n",
        "features = range(num)\n",
        "plt.bar(features, pca.explained_variance_ratio_, color='black')\n",
        "plt.xlabel('PCA features')\n",
        "plt.ylabel('variance %')\n",
        "plt.xticks(features)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRG5l267SurY"
      },
      "outputs": [],
      "source": [
        "#Visualize the first two components\n",
        "PCA_components = pd.DataFrame(two_dim)\n",
        "plt.scatter(PCA_components[0], PCA_components[1], alpha=.1, color='black')\n",
        "plt.xlabel('PCA 1')\n",
        "plt.ylabel('PCA 2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKgMuJclSyYJ"
      },
      "outputs": [],
      "source": [
        "#Visualize the 3rd and 4th components\n",
        "#this seems to have some sort of 2 dense areas\n",
        "PCA_components = pd.DataFrame(two_dim)\n",
        "plt.scatter(PCA_components[2], PCA_components[3], alpha=.1, color='black')\n",
        "plt.xlabel('PCA 3')\n",
        "plt.ylabel('PCA 4')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-QyuUejzflM"
      },
      "outputs": [],
      "source": [
        "distortions = []\n",
        "for k in range(1,10):\n",
        "    model = KMeans(n_clusters=k)\n",
        "    model.fit(tfidf)\n",
        "    distortions.append(model.inertia_)\n",
        "\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.plot(range(1,10), distortions, 'bx-')\n",
        "plt.ylabel('Distortion')\n",
        "plt.xlabel('k value')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHbKXdQrZiR1"
      },
      "outputs": [],
      "source": [
        "plt.style.use('ggplot')\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(20,10)\n",
        "\n",
        "# color map for NUMBER_OF_CLUSTERS we have\n",
        "cmap = {0: 'green', 1: 'blue', 2: 'red', 3: 'yellow', 4: \"pink\", 5:\"black\"}\n",
        "\n",
        "# group by clusters and scatter plot every cluster\n",
        "# with a colour and a label\n",
        "for group in np.unique(clusters):\n",
        "    ix = np.where(clusters == group)\n",
        "    ax.scatter(scatter_x[ix], scatter_y[ix], c=cmap[group], label=group)\n",
        "\n",
        "ax.legend()\n",
        "plt.xlabel(\"PCA 0\")\n",
        "plt.ylabel(\"PCA 1\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Uc4cz0uTzWx"
      },
      "outputs": [],
      "source": [
        "#plot without group 0\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(20,10)\n",
        "\n",
        "# color map for NUMBER_OF_CLUSTERS we have\n",
        "cmap = {0: 'green', 1: 'blue', 2: 'red', 3: 'yellow', 4: \"pink\", 5:\"black\"}\n",
        "\n",
        "# group by clusters and scatter plot every cluster\n",
        "# with a colour and a label\n",
        "for group in range(1,6):\n",
        "    ix = np.where(clusters == group)\n",
        "    ax.scatter(scatter_x[ix], scatter_y[ix], c=cmap[group], label=group)\n",
        "\n",
        "ax.legend()\n",
        "plt.xlabel(\"PCA 0\")\n",
        "plt.ylabel(\"PCA 1\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7zPeuO_UASJ"
      },
      "outputs": [],
      "source": [
        "# can see a more clear split between certain groups like \n",
        "plt.style.use('ggplot')\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(20,10)\n",
        "\n",
        "# color map for NUMBER_OF_CLUSTERS we have\n",
        "cmap = {0: 'green', 1: 'blue', 2: 'red', 3: 'yellow', 4: \"pink\", 5:\"black\"}\n",
        "\n",
        "# group by clusters and scatter plot every cluster\n",
        "# with a colour and a label\n",
        "for group in [3,4,5]:\n",
        "    ix = np.where(clusters == group)\n",
        "    ax.scatter(scatter_x[ix], scatter_y[ix], c=cmap[group], label=group)\n",
        "\n",
        "ax.legend()\n",
        "plt.xlabel(\"PCA 0\")\n",
        "plt.ylabel(\"PCA 1\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling"
      ],
      "metadata": {
        "id": "DDtKsWzjdn2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to begin with a Bag-of-Words approach to predict motivation labels for each post. We will investigate Naive Bayes and Logistic Regression as models. Then we will train a sequential model."
      ],
      "metadata": {
        "id": "-AElt4r8d-RE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vD_w11fKlbY1"
      },
      "outputs": [],
      "source": [
        "print(tfidf.shape)\n",
        "print(labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DN4MiXRYh_jK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
        "# from sklearn.metrics import roc_curve, auc, roc_auc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Naive Bayes"
      ],
      "metadata": {
        "id": "Z6wgzv4hjjwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tfidf, labels, test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "afgOkB8tf0mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ku_PSUDPzM-B"
      },
      "outputs": [],
      "source": [
        "#Naive Bayes: Baseline Model with no smoothing\n",
        "\n",
        "nb_tfidf = MultinomialNB(alpha = 0)\n",
        "nb_tfidf.fit(X_train, y_train)\n",
        "y_predict = nb_tfidf.predict(X_test)\n",
        "y_prob = nb_tfidf.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(classification_report(y_test,y_predict))\n",
        "mat = confusion_matrix(y_test, y_predict)\n",
        "print('Confusion Matrix:\\n', mat)\n",
        "\n",
        "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('predicted label')\n",
        "plt.ylabel('true label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kli-X7fph1wH"
      },
      "outputs": [],
      "source": [
        "#hyperparameter tuning\n",
        "#Naive Bayes: with add-1 smoothing\n",
        "\n",
        "nb_tfidf = MultinomialNB()\n",
        "nb_tfidf.fit(X_train, y_train)\n",
        "y_predict = nb_tfidf.predict(X_test)\n",
        "y_prob = nb_tfidf.predict_proba(X_test)[:,1]\n",
        "print(classification_report(y_test,y_predict))\n",
        "mat = confusion_matrix(y_test, y_predict)\n",
        "print('Confusion Matrix:\\n', mat)\n",
        "\n",
        "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('predicted label')\n",
        "plt.ylabel('true label')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes: with add-1 smoothing\n",
        "#try a 70-30 train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf, labels, test_size=0.3, shuffle=True)\n",
        "\n",
        "nb_tfidf = MultinomialNB()\n",
        "nb_tfidf.fit(X_train, y_train)\n",
        "y_predict = nb_tfidf.predict(X_test)\n",
        "y_prob = nb_tfidf.predict_proba(X_test)[:,1]\n",
        "print(classification_report(y_test,y_predict))\n",
        "mat = confusion_matrix(y_test, y_predict)\n",
        "print('Confusion Matrix:\\n', mat)\n",
        "\n",
        "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('predicted label')\n",
        "plt.ylabel('true label')"
      ],
      "metadata": {
        "id": "OY8L0GlRgs0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Logistic Regression"
      ],
      "metadata": {
        "id": "Dru1s9Sfjom3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tfidf, labels, test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "w1DLWBnBjs3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1skmG-hBME4"
      },
      "outputs": [],
      "source": [
        "lg_tfidf = LogisticRegression()\n",
        "lg_tfidf.fit(X_train, y_train)\n",
        "y_predict = lg_tfidf.predict(X_test)\n",
        "y_prob = lg_tfidf.predict_proba(X_test)[:,1]\n",
        "print(classification_report(y_test,y_predict))\n",
        "mat = confusion_matrix(y_test, y_predict)\n",
        "print('Confusion Matrix:\\n', mat)\n",
        "\n",
        "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('predicted label')\n",
        "plt.ylabel('true label')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lg2_tfidf = LogisticRegression(solver = 'liblinear', random_state = 20, penalty = 'l2')\n",
        "\n",
        "lg2_tfidf.fit(X_train, y_train)\n",
        "y_predict2 = lg2_tfidf.predict(X_test)\n",
        "y_prob2 = lg2_tfidf.predict_proba(X_test)[:,1]\n",
        "print(classification_report(y_test,y_predict2))\n",
        "mat = confusion_matrix(y_test, y_predict2)\n",
        "print('Confusion Matrix:\\n', mat)\n",
        "\n",
        "sns.heatmap(mat, square=True, annot=True, fmt='d', cbar=False)\n",
        "plt.xlabel('predicted label')\n",
        "plt.ylabel('true label')"
      ],
      "metadata": {
        "id": "WQEGHzz0g0V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AO3sHuitHJWh"
      },
      "source": [
        "#### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUzRrB6bLgBH"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "vocab_size = 5000\n",
        "embedding_dim = 64\n",
        "max_length = 200\n",
        "trunc_type = 'post'\n",
        "padding_type = 'post'\n",
        "oov_tok = '<OOV>'\n",
        "training_portion = .8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tlsyQRLLgBK"
      },
      "outputs": [],
      "source": [
        "labels = labels.astype(int)\n",
        "docs = []\n",
        "for doc in df['body']:\n",
        "  for word in STOPWORDS:\n",
        "    token = ' ' + word + ' '\n",
        "    doc = doc.replace(token, ' ')\n",
        "    doc = doc.replace(' ', ' ')\n",
        "  docs.append(doc)\n",
        "print(len(labels))\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZPIWjGrLgBZ"
      },
      "outputs": [],
      "source": [
        "print(set(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBF3KPX5LgBO"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(train_docs)\n",
        "word_index = tokenizer.word_index\n",
        "dict(list(word_index.items())[0:20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPjP6ib_LgBQ"
      },
      "outputs": [],
      "source": [
        "sequences = tokenizer.texts_to_sequences(docs)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYFRDkkzLgBU"
      },
      "outputs": [],
      "source": [
        "label_seq = np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the model with an embedding layer, a bidirectional layer, a droupout layer to avoid overfitting, and a softmax layer."
      ],
      "metadata": {
        "id": "Al_FzaC7lXM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(Bidirectional(LSTM(embedding_dim)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "l1KsMuA2lWlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Weq1pr0MLgBa"
      },
      "source": [
        "We didn't do one-hot encoding, so used categorical crossentropy for loss. Important to note that these labels are not ordered and do not have any numeric relationship."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ow_TJTL0LgBb"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(padded, label_seq, epochs=10, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFtVFDt3LgBc"
      },
      "outputs": [],
      "source": [
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "  \n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TejQz0RfFYGw"
      },
      "source": [
        "### Time Sequential Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nCiinggoMZk"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timezone\n",
        "\n",
        "utcs = (df['created_utc'].astype(int))\n",
        "ts = []\n",
        "month = []\n",
        "for u in utcs:\n",
        "   t = datetime.fromtimestamp(u, tz=timezone.utc)\n",
        "   ts.append(t)\n",
        "   month.append(datetime.strftime(t, '%m'))\n",
        "\n",
        "df['timestamp'] = ts\n",
        "df['month'] = month\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHT8xc-xC37r"
      },
      "outputs": [],
      "source": [
        "df.sort_values('month')\n",
        "df['month'] = df['month'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Onlow-Smu-hK"
      },
      "outputs": [],
      "source": [
        "sns.countplot(x='month', hue='class', data=df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LanguageLearning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}